---
{"dg-publish":true,"permalink":"/philip-morgan-research-notes/ssr-guide-public-preview/"}
---

This is a public preview of _The Small-Scale Research Guide_. Currently in-progress.


<div class="transclusion">

# The Potential Of Small-Scale Research


[Get the examples I have in front of readers early on in the book :)]

This was merely the first example I could find of a particular genre that is well-represented on the Internet:

![vivaldi_2J3S0446jt.png](file:///C:%5CUsers%5Cphili%5CDocuments%5CShareX%5CScreenshots%5C2022-03%5Cvivaldi_2J3S0446jt.png)

You see what's going on here, right? The tweeter is mocking those who confidently espouse opinions on Twitter without institutional backing for those opinions.

This is a simplification of a more complex problem:

1: Deep genuine experts really don't want their expertise undermined by folks farming likes and shares on social media platforms.

2: It is actually possible to mis-use tools we don't have the proper training to master, and that mis-use can lead to harm.

So @TK:handle of twitter poster is -- in their own cartoonish like-farming way -- acting in defense of the honor and place of real expertise. This is a big part of the cultural backdrop we consider when we think about small-scale research.

If I buy a $5000 vintage Martin guitar to play 3-chord songs on the weekend, nobody's really been harmed by my usage of this tool, it's just that the tool's potential is utterly wasted on my lack of ability to play it well. If my wife complains of abdominal pain and I try to remove her appendix with a $5 X-acto knife, I'm mis-using a tool in a way that almost certainly *will* harm her.

But what if I create a survey instrument, field it and get a few hundred data points, and start advising clients based on what I've learned from that survey? Am I mis-using that tool in a way that can lead to harm?

When we consider doing research, too many of us fear something like the tweet I included above being aimed at us. Either a well-trained master of the tool spots an error that was invisible to us and calls us out, a social media like-farmer takes a pot shot at us, or we cause actual harm to another despite our intentions to help. These fears are not entirely baseless, but they are based on a misapprehension of the world of research that I hope to correct in this guide.

I hope to illuminate a small corner of the much larger world of research: the small-scale research corner. The value of using small-scale research to help your clients make better decisions is high, and -- if you're careful with your usage of the tools -- the risk of causing harm is low.

## Data Is Powerful

Our culture worships data. And rightly so. Data combined with human ingenuity and sweat is a godlike tool that's pulled us out of a nasty, brutish, and short existence into across-the-board increases in comfort, wealth, health, and technological & human potential. But cults form around deities, and so data is more than just a powerful tool.

Data can also be a way to justify taking a quick shortcut from an inner emotional sense to a haughty, external certainty. We can go further and use data as a social cudgel to attack enemies. Or we can assemble enough data to feel that we walk about in priestly vestments, closer to the divine than the unwashed masses.

Data is powerful. But data is not an unalloyed good, nor is it always the best tool to guide decisions. Data can only be as good as those who produce and consume it. But data _can be_ an instrument for improving decision making and wellbeing, and an ability to produce and consume it should be accessible to us, not just large well-funded institutions and companies.  For us to do that, we should start with understanding the broader landscape of research.

## The 5,000-Foot View

We'll roughly divide the world of research into 3 not-equally-sized sectors:

1. Academic/Scientific Research
2. Small-Scale Research
3. Business Research

@TODO: illustrative sketch

Academic/Scientific research is what we are most familiar with. 

5-second 5,000-foot view
	Academic/Scientific Research
	Small-Scale Research
	Business Research
Why small-scale research?
	Forces a literature review, which is often the crash course we need in prior art.
	Forces us to think about context (if we haven't already) in a deeper/more serious way
		Ex: Guillaume's lit review uncovering no prior art in the business world but similar prior art in a different domain.
	Can be used to create IP.
	Gives a valuable POV angle
		Can help move our POV away from experience and towards data, or give us more range from experience to data.
	Helps us help our clients make better decisions
		This is really the bottom line here, and the ultimate reason to do this small-scale research.
		Data is a story we tell ourselves about why we decided a certain way
			This is an argument both for getting more fluent at creating and using data, and an argument for humility around the whole idea of data.
			"Alchemy" by Rory Sutherland is a fun, worthwhile read here.
			"How to Measure Anything" by Douglas Hubbard is a much less fun, but equally worthwhile counterbalancing read.
		A spirit of *service* is important here.
Why don't we do more small-scale research?
	We mis-aprehend research generally and business research specifically.
	We may have no formal training doing it
		I did one small-scale research project involving surveys and SPSS as part of a senior Political Science thesis project.
	We are intimidated by it.
	We have few examples of our peers doing it.
	We have some examples of small-scale research used for marketing, but that's just one of several ways research can be leveraged and examples where it's used for decision support are less visible to us and therefore more mysterious.
	We practice an unlicensed profession, and so there's little incentive for us to up our game beyond what improvisation, gut feel, past experience, and best-ish practices suggest.
All together, these factors cause us to under-utilize research
	The act of doing the research â€” even if nothing impressive comes out the other end â€” is a powerful growth experience.
So, let's talk about small-scale research!

</div>


<div class="transclusion">

# What Is Research Generally, And Business Research Specifically?

Small-scale research is accelerated, focused learning. 

Research in general is an attempt to understand causation.




Research generally" Understand causation
	Business context:
		Risk management:
			Outcomes: Reducing uncertainty/establishing probabilities
				You could think of this as simply: measuring something that's under-measured.
			Examples
				Cost of government procurement system.
				Risks of flooding in mining operations.
				Impact of pesticides regulation.
				IT security.
			Environment: Closed systems
				Youâ€™re able to control and measure almost every aspect of the system.
			Method
				â€œHubbard-style" measurement
					Define decision.
					Model current uncertainty.
					Compute value of information.
					Measure, keeping in mind the uncertainty-reduction mindset.
					Optimize decision, potentially rinse & repeat.
				Deductive
					Theory -> Measurement/Testing -> Confirmed/Denied Hypothesis.
					You're not working with a null hypothesis theory, but you generally are working with *relatively* simplistic hypotheses that benefit from the relatively simple nature of the closed system surrounding the area of unknown/risk.
				Quantitative
					Risk management often deals with probabilities and uncertainty reduction, so quant methods -- with surprisingly small data sets -- are usable
						When we talk about small data sets, remember the context: not trying to steer public policy, etc.
			Useful reading
				Douglas Hubbard, â€œHow to Measure Anythingâ€.
				Sam Savage, â€œThe Flaw of Averages".
		Innovation:
			Outcome: Generating new options/narrative richness
				Based on the *belief* that empathy precedes innovation.
				Elizabeth Gilbert story about Tom Waits.
			Examples
				Snickers
					Discovered another purpose for consuming their product.
				YourGrocer
					Discovered actual customer.
			Environment: Open systems
				You are unable to control, measure, or even fully understand the relationships between elements of the system, or the system youâ€™re investigating and other related systems.
			Method
				JTBD/Customer development/Ethnography.
				Inductive
					Observation -> Pattern Recognition ->  Theory/Model/Conclusion.
				Qualitative.
			Useful reading
				Alan Klement, â€œWhen Kale and Coffee Compete".
				Indi Young's work.
		Better decision making:
			This is distinct from the risk management approach because you're (largely) an outsider
				The risk management approach presumes a certain level of insider access you may not have, and a certain level of familiarity with the system you may not have.
			Mixed methods:
				Scale/causation
					Might be understood as measuring a specific phenomenon, with an effort to control or create homogeneity in the surrounding context.
				and
				Coherence/focus
					MIght be understood as exploring the context within which a specific phenomenon occurs, with an effort to understand the natural variation and diversity in that context.
			With this approach, you may blend elements of both the risk management style and the innovation style.
				The focus is on the relatively closed system of a specific business decision, not the wide-open vista of innovation.
				But, because you lack the benefits (and drawbacks!) of being an insider, the research approach might look more like an inductive/qual/exploratory approach (but not always!)
			Useful reading
				Sam Ladner, â€œMixed Methods".
	Academic/Scientific context:
		Not relevant to us here except where it spins off commoditized and-also-usable-by-us best practices, or methodology approaches we can adapt.

</div>


<div class="transclusion">

# Where Does Small-Scale Research Fit INto The Broader Research Landscape?

Small-Scale Research:
	Focused on enabling (better) decision making. As you've seen, that incorporates elements of both risk management and innovation research.
	The motive of service must supersede all other motives.
	To make it do-able, we sacrifice statistical rigor and embrace small sample size, mixed methods.
	If necessary, we look at it as a pilot/prototype or an MVP of more robust research we'll do later, or perhaps as the first "sprint" in a long-running iterative process.
Warnings:
	A question:
		Would you want a new vaccine tested by someone who will never use it on themselves?
	You need skin in the game
		This motivates context-gathering, which is critical to sanity-checking your findings.
		Guillaume story: "Are you OK if this invalidates your work's claimed value prop?"
	You need to connect your research with a decision
		Otherwise you run the risk of useless "state of the industry" surveys.
		These have marketing/visibility value, but much less decision-enabling value and less potential to create IP.
Summary
	Motive: understand causation.
	4 contexts
		Risk management.
		Innovation.
		Hybrid.
		Academic/Scientific.
	We are, coming from a spirit of service, trying to help our clients make better decisions.


</div>


<div class="transclusion">

# Research Methods And Design

## Design/Meta-Methods

- **1: Measuring prevalence**
	- ex: NPS (Among those who respond to this survey, how prevalent are the promoters vs. detractors?)
	- ex: We think employee morale is a problem, but don't know how big a problem. Let's measure how many employees are satisfied vs. dissatisfied with their workplace.
	- Tends to reduce down into a dashboard-level number of "great/good/OK/bad/emergency". Tries to abstract complex reality into a number.
- **2: Measuring the under-measured**
	- Similar to measuring prevalence, but worth calling out separately because having this as the goal will trickle down into slightly or very different design/methods
	- ex: what would it cost us if supply chain disruptions shut down our production for a day, week, month, etc?
	- Often will be a _component_ of a larger or more complex analysis or decision. (ex: is the cost and likelihood of that potential supply chain shutdown big enough that we invest in redundancy?)
- **3: Toy version of more complex system: does input X produce/fail to produce output/effect Y?**
	- ex: if this professor who is from Europe behaves in a warm way with one group of students and a cold way with others, will there be a halo effect?
	- ex: if we put this experimental drug into some tissue in a petri dish, will X happen?
	- 
- **4: Structured observation that seeks to comprehend and make sense of the behavior, nuance, context, and variation within a phenomenon, system, or form of thinking.**
- Overall:
	- The 3 forms of research design (meta-method) are:
		- Measurement
		- Testing (a hypothesis)
		- Observing -> sense-making/understanding

## Specific Methods (is Tools a better word?)

TODO

- [ ] Skip through my collection of research papers, make sure I haven't missed any high-level category of meta-method
</div>


<div class="transclusion">

# Research Methods Suited To Small-Scale Research


</div>


<div class="transclusion">

# Research Questions Generally


</div>


<div class="transclusion">

# Formulating A Good Small-Scale Research Question


</div>


<div class="transclusion">

# Designing A Small-Scale Research Project


</div>


<div class="transclusion">

# Executing A Small-Scale Research Project


</div>


<div class="transclusion">

# Making Small-Scale Research Findings Useful


</div>



## TODO

- [ ] #0-task Next step: reference TEI Talks to sketch out chapter outlines ðŸ“… 2022-03-11

## Notes

- Running examples:
	- If you sampled the prevalence of deer at my house at 5 to 6am and 4 to 6pm, you'd get a hugely sample-biased result that over-counts.
- [ ] If you sampled the prevalence of birds in my wife's bird sanctuary the moment I open the door to take the trash out, you'd hugely under-count, again due to sampling bias.
- [ ] test git plugin
